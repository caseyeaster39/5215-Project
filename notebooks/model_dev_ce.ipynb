{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed3433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import GammaRegressor, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor\n",
    "\n",
    "\n",
    "# Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Multioutput\n",
    "from sklearn.multioutput import MultiOutputRegressor as MOR\n",
    "\n",
    "# Scoring\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Model Persistence\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1093d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "df = pd.read_csv('../../train_with_zip_pop_weather825000.csv')\n",
    "\n",
    "features = [\"Hour\", \"Weekend\", \"Month\", \"radius_in_miles\", \"population\", \n",
    "            \"population_density\", \"land_area_in_sqmi\", \"water_area_in_sqmi\", \n",
    "            \"housing_units\", \"occupied_housing_units\", \"median_home_value\", \n",
    "            \"median_household_income\", \"temp\", \"dwpt\", \"rhum\", \"prcp\", \n",
    "            \"wdir\", \"wspd\", \"pres\", \"coco\"]\n",
    "\n",
    "percentiles = ['p20', 'p40', 'p50', 'p60', 'p80']\n",
    "targets = [f\"TotalTimeStopped_{percentile}\" for percentile in percentiles]\n",
    "\n",
    "X = df[features]\n",
    "y = df[targets]\n",
    "\n",
    "X_selection, y_selection = X.sample(n=10000), y.sample(n=10000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e3d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputation_mean\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),    # All features are numerical\n",
    "        (\"decomposition\", PCA())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model fitting\n",
    "def fit_model(model, X, y, grid_search=True):\n",
    "    print(f\"Fitting {model['regr']}\")\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocess', preprocessor),\n",
    "            ('regression', MOR(model['regr']))\n",
    "        ]\n",
    "    )\n",
    "    param_grid = model['params']\n",
    "    \n",
    "    if grid_search:\n",
    "        gs = GridSearchCV(estimator=pipe,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=3,\n",
    "                          scoring=\"neg_mean_absolute_error\",\n",
    "                          n_jobs=-1,\n",
    "                          verbose=2\n",
    "                         )\n",
    "\n",
    "        gs.fit(X, y)        \n",
    "        return gs\n",
    "    else:\n",
    "        pipe.fit(X, y)\n",
    "        return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8021338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models and desired parameters\n",
    "models = {\n",
    "    'sgd': {\n",
    "        'regr': SGDRegressor(),\n",
    "        'params': {\n",
    "            'preprocess__decomposition__n_components': [2, 3, 5],\n",
    "            'regression__estimator__penalty': [\"l2\", \"l1\"],\n",
    "            'regression__estimator__alpha': [.0001, .0005, .001],\n",
    "            'regression__estimator__learning_rate': [\"optimal\"],\n",
    "            'regression__estimator__max_iter': [10000]\n",
    "        }\n",
    "    },\n",
    "    'rfr': {\n",
    "        'regr': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'preprocess__decomposition__n_components': [2, 3, 5],\n",
    "            'regression__estimator__n_estimators': [50, 100, 250],\n",
    "            'regression__estimator__min_samples_leaf': [1, 5, 25]     \n",
    "        }\n",
    "    },\n",
    "    'gbr': {\n",
    "        'regr': GradientBoostingRegressor(),\n",
    "        'params': {\n",
    "            'preprocess__decomposition__n_components': [2, 3, 5],\n",
    "            'regression__estimator__learning_rate': [50, 100, 250],\n",
    "            'regression__estimator__n_estimators': [50, 100, 250] \n",
    "        }\n",
    "    },\n",
    "    'abr': {\n",
    "        'regr': AdaBoostRegressor(),\n",
    "        'params': {\n",
    "            'preprocess__decomposition__n_components': [2, 3, 5],\n",
    "            'regression__estimator__learning_rate': [50, 100, 250],\n",
    "            'regression__estimator__n_estimators': [25, 50, 100]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca923774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SGDRegressor()\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "\n",
      "Best score for SGDRegressor(): -1.2879217563110025e+19\n",
      "Best parameters for SGDRegressor(): {'preprocess__decomposition__n_components': 3, 'regression__estimator__alpha': 0.001, 'regression__estimator__learning_rate': 'optimal', 'regression__estimator__max_iter': 10000, 'regression__estimator__penalty': 'l2'}\n",
      "#############################################################\n",
      "Fitting RandomForestRegressor()\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "\n",
      "Best score for RandomForestRegressor(): -11.461904528346073\n",
      "Best parameters for RandomForestRegressor(): {'preprocess__decomposition__n_components': 2, 'regression__estimator__min_samples_leaf': 25, 'regression__estimator__n_estimators': 250}\n",
      "#############################################################\n",
      "Fitting GradientBoostingRegressor()\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-2.20876952e+084 -3.61144115e+165              nan -4.13061911e+099\n",
      " -9.12898503e+195              nan -4.40781424e+119 -9.81934722e+234\n",
      "              nan -2.34514844e+084 -2.46455961e+163              nan\n",
      " -4.38608366e+099 -4.95639742e+192              nan -4.68014884e+119\n",
      " -3.93760465e+226              nan -2.14885769e+084 -2.01375823e+161\n",
      "              nan -4.01881752e+099 -1.11112522e+186              nan\n",
      " -4.28819820e+119 -3.18199256e+226              nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\casey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:978: RuntimeWarning: overflow encountered in square\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best score for GradientBoostingRegressor(): -2.148857687731374e+84\n",
      "Best parameters for GradientBoostingRegressor(): {'preprocess__decomposition__n_components': 5, 'regression__estimator__learning_rate': 50, 'regression__estimator__n_estimators': 50}\n",
      "#############################################################\n",
      "Fitting AdaBoostRegressor()\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "\n",
      "Best score for AdaBoostRegressor(): -12.479259173667819\n",
      "Best parameters for AdaBoostRegressor(): {'preprocess__decomposition__n_components': 2, 'regression__estimator__learning_rate': 100, 'regression__estimator__n_estimators': 100}\n",
      "#############################################################\n"
     ]
    }
   ],
   "source": [
    "# Model selection and hyperparameter tuning\n",
    "gs_models = {}\n",
    "for model in models:\n",
    "    gs_models[model] = fit_model(models[model], X_selection, y_selection)\n",
    "    print(f\"\\nBest score for {models[model]['regr']}: {gs_models[model].best_score_}\") \n",
    "    print(f\"Best parameters for {models[model]['regr']}: {gs_models[model].best_params_}\")    \n",
    "    print('#############################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f4db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting AdaBoostRegressor()\n",
      "Fitting RandomForestRegressor()\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Full training, use the same abbreviation used in models dictionary above\n",
    "for top-level key and maintanin the dictionary structure as shown below\n",
    "'''\n",
    "chosen_models = {\n",
    "    'abr': {\n",
    "        'regr': None,\n",
    "        'params': None,\n",
    "        'model': None,\n",
    "        'mae': None\n",
    "    },\n",
    "    'rfr': {\n",
    "        'regr': None,\n",
    "        'params': None,\n",
    "        'model': None,\n",
    "        'mae': None\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for model in chosen_models:\n",
    "    chosen_models[model]['regr'] = models[model]['regr']\n",
    "    chosen_models[model]['params'] = gs_models[model].best_params_.copy()\n",
    "    \n",
    "    chosen_models[model]['model'] = fit_model(chosen_models[model], X_train, y_train, grid_search=False)\n",
    "    preds = chosen_models[model]['model'].predict(X_test)\n",
    "    chosen_models[model]['mae'] = mean_absolute_error(y_test, preds)\n",
    "    \n",
    "    dump(chosen_models[model], f'./model_cache/{model}.joblib') \n",
    "    mae = chosen_models[model]['mae']\n",
    "    print(f'{model} score: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08a22cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.076917667779583\n",
      "11.487551477587072\n"
     ]
    }
   ],
   "source": [
    "# Loading, using stored models\n",
    "for model in chosen_models:\n",
    "    load_model = load(f'./model_cache/{model}.joblib')\n",
    "    preds = load_model['model'].predict(X_test)\n",
    "    print(mean_absolute_error(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
